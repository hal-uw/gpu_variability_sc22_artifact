//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29373293
// Cuda compilation tools, release 11.2, V11.2.67
// Based on NVVM 7.0.1
//

.version 7.2
.target sm_52
.address_size 64

	// .globl	transformKernel
.global .texref tex;
.global .align 4 .b8 __cudart_i2opi_f[24] = {65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .entry transformKernel(
	.param .u64 transformKernel_param_0,
	.param .u32 transformKernel_param_1,
	.param .u32 transformKernel_param_2,
	.param .f32 transformKernel_param_3
)
{
	.local .align 4 .b8 	__local_depot0[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<45>;
	.reg .f32 	%f<138>;
	.reg .b32 	%r<232>;
	.reg .f64 	%fd<9>;
	.reg .b64 	%rd<90>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd33, [transformKernel_param_0];
	ld.param.u32 	%r105, [transformKernel_param_1];
	ld.param.u32 	%r106, [transformKernel_param_2];
	ld.param.f32 	%f47, [transformKernel_param_3];
	mov.u32 	%r107, %ntid.x;
	mov.u32 	%r108, %ctaid.x;
	mov.u32 	%r109, %tid.x;
	mad.lo.s32 	%r110, %r108, %r107, %r109;
	mov.u32 	%r111, %ntid.y;
	mov.u32 	%r112, %ctaid.y;
	mov.u32 	%r113, %tid.y;
	mad.lo.s32 	%r114, %r112, %r111, %r113;
	cvt.rn.f32.u32 	%f48, %r110;
	cvt.rn.f32.s32 	%f49, %r105;
	div.rn.f32 	%f50, %f48, %f49;
	cvt.rn.f32.u32 	%f51, %r114;
	cvt.rn.f32.s32 	%f52, %r106;
	div.rn.f32 	%f53, %f51, %f52;
	add.f32 	%f1, %f50, 0fBF000000;
	add.f32 	%f2, %f53, 0fBF000000;
	mul.f32 	%f54, %f47, 0f3F22F983;
	cvt.rni.s32.f32 	%r231, %f54;
	cvt.rn.f32.s32 	%f55, %r231;
	mov.f32 	%f56, 0fBFC90FDA;
	fma.rn.f32 	%f57, %f55, %f56, %f47;
	mov.f32 	%f58, 0fB3A22168;
	fma.rn.f32 	%f59, %f55, %f58, %f57;
	mov.f32 	%f60, 0fA7C234C5;
	fma.rn.f32 	%f135, %f55, %f60, %f59;
	abs.f32 	%f4, %f47;
	setp.leu.f32 	%p1, %f4, 0f47CE4780;
	mov.u32 	%r210, %r231;
	mov.f32 	%f126, %f135;
	@%p1 bra 	LBB0_10;

	setp.eq.f32 	%p2, %f4, 0f7F800000;
	@%p2 bra 	LBB0_9;
	bra.uni 	LBB0_2;

LBB0_9:
	mov.f32 	%f63, 0f00000000;
	mul.rn.f32 	%f126, %f47, %f63;
	mov.u32 	%r210, %r231;
	bra.uni 	LBB0_10;

LBB0_2:
	mov.b32 	%r116, %f47;
	shl.b32 	%r117, %r116, 8;
	or.b32  	%r2, %r117, -2147483648;
	add.u64 	%rd36, %SP, 0;
	add.u64 	%rd79, %SPL, 0;
	mov.u64 	%rd80, 0;
	mov.u32 	%r204, 0;
	mov.u64 	%rd78, __cudart_i2opi_f;

LBB0_3:
	.pragma "nounroll";
	ld.global.nc.u32 	%r118, [%rd78];
	mad.wide.u32 	%rd37, %r118, %r2, %rd80;
	shr.u64 	%rd80, %rd37, 32;
	st.local.u32 	[%rd79], %rd37;
	add.s64 	%rd79, %rd79, 4;
	add.s64 	%rd78, %rd78, 4;
	add.s32 	%r204, %r204, 1;
	setp.ne.s32 	%p3, %r204, 6;
	@%p3 bra 	LBB0_3;

	and.b32  	%r5, %r116, -2147483648;
	cvta.to.local.u64 	%rd39, %rd36;
	st.local.u32 	[%rd39+24], %rd80;
	bfe.u32 	%r120, %r116, 23, 8;
	add.s32 	%r121, %r120, -128;
	and.b32  	%r6, %r121, 31;
	shr.u32 	%r122, %r121, 5;
	mul.wide.u32 	%rd40, %r122, 4;
	sub.s64 	%rd8, %rd39, %rd40;
	ld.local.u32 	%r205, [%rd8+24];
	ld.local.u32 	%r206, [%rd8+20];
	setp.eq.s32 	%p4, %r6, 0;
	@%p4 bra 	LBB0_6;

	mov.u32 	%r123, 32;
	sub.s32 	%r124, %r123, %r6;
	shr.u32 	%r125, %r206, %r124;
	shl.b32 	%r126, %r205, %r6;
	add.s32 	%r205, %r125, %r126;
	ld.local.u32 	%r127, [%rd8+16];
	shr.u32 	%r128, %r127, %r124;
	shl.b32 	%r129, %r206, %r6;
	add.s32 	%r206, %r128, %r129;

LBB0_6:
	shr.u32 	%r130, %r206, 30;
	shl.b32 	%r131, %r205, 2;
	or.b32  	%r208, %r130, %r131;
	shl.b32 	%r209, %r206, 2;
	shr.u32 	%r132, %r208, 31;
	shr.u32 	%r133, %r205, 30;
	add.s32 	%r15, %r132, %r133;
	setp.eq.s32 	%p5, %r132, 0;
	mov.u32 	%r207, %r5;
	@%p5 bra 	LBB0_8;

	not.b32 	%r134, %r208;
	neg.s32 	%r16, %r209;
	setp.eq.s32 	%p6, %r209, 0;
	selp.u32 	%r135, 1, 0, %p6;
	add.s32 	%r208, %r135, %r134;
	xor.b32  	%r207, %r5, -2147483648;
	mov.u32 	%r209, %r16;

LBB0_8:
	cvt.u64.u32 	%rd41, %r208;
	cvt.u64.u32 	%rd42, %r209;
	bfi.b64 	%rd43, %rd41, %rd42, 32, 32;
	cvt.rn.f64.s64 	%fd1, %rd43;
	mul.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f61, %fd2;
	neg.f32 	%f62, %f61;
	setp.eq.s32 	%p7, %r207, 0;
	selp.f32 	%f126, %f61, %f62, %p7;
	setp.eq.s32 	%p8, %r5, 0;
	neg.s32 	%r136, %r15;
	selp.b32 	%r210, %r15, %r136, %p8;

LBB0_10:
	add.s32 	%r24, %r210, 1;
	and.b32  	%r25, %r24, 1;
	setp.eq.s32 	%p9, %r25, 0;
	selp.f32 	%f8, %f126, 0f3F800000, %p9;
	mul.rn.f32 	%f9, %f126, %f126;
	mov.f32 	%f127, 0fB94D4153;
	@%p9 bra 	LBB0_12;

	mov.f32 	%f65, 0fBAB607ED;
	mov.f32 	%f66, 0f37CBAC00;
	fma.rn.f32 	%f127, %f66, %f9, %f65;

LBB0_12:
	selp.f32 	%f67, 0f3C0885E4, 0f3D2AAABB, %p9;
	fma.rn.f32 	%f68, %f127, %f9, %f67;
	selp.f32 	%f69, 0fBE2AAAA8, 0fBEFFFFFF, %p9;
	fma.rn.f32 	%f70, %f68, %f9, %f69;
	mov.f32 	%f71, 0f00000000;
	fma.rn.f32 	%f72, %f9, %f8, %f71;
	fma.rn.f32 	%f128, %f70, %f72, %f8;
	and.b32  	%r137, %r24, 2;
	setp.eq.s32 	%p11, %r137, 0;
	@%p11 bra 	LBB0_14;

	mov.f32 	%f74, 0fBF800000;
	fma.rn.f32 	%f128, %f128, %f74, %f71;

LBB0_14:
	mov.u32 	%r217, %r231;
	mov.f32 	%f129, %f135;
	@%p1 bra 	LBB0_24;

	setp.eq.f32 	%p13, %f4, 0f7F800000;
	@%p13 bra 	LBB0_23;
	bra.uni 	LBB0_16;

LBB0_23:
	mul.rn.f32 	%f129, %f47, %f71;
	mov.u32 	%r217, %r231;
	bra.uni 	LBB0_24;

LBB0_16:
	mov.b32 	%r26, %f47;
	bfe.u32 	%r139, %r26, 23, 8;
	add.s32 	%r27, %r139, -128;
	shl.b32 	%r140, %r26, 8;
	or.b32  	%r28, %r140, -2147483648;
	shr.u32 	%r29, %r27, 5;
	add.u64 	%rd46, %SP, 0;
	add.u64 	%rd82, %SPL, 0;
	mov.u64 	%rd83, 0;
	mov.u32 	%r211, 0;
	mov.u64 	%rd81, __cudart_i2opi_f;

LBB0_17:
	.pragma "nounroll";
	ld.global.nc.u32 	%r141, [%rd81];
	mad.wide.u32 	%rd47, %r141, %r28, %rd83;
	shr.u64 	%rd83, %rd47, 32;
	st.local.u32 	[%rd82], %rd47;
	add.s64 	%rd82, %rd82, 4;
	add.s64 	%rd81, %rd81, 4;
	add.s32 	%r211, %r211, 1;
	setp.ne.s32 	%p14, %r211, 6;
	@%p14 bra 	LBB0_17;

	and.b32  	%r32, %r26, -2147483648;
	cvta.to.local.u64 	%rd49, %rd46;
	st.local.u32 	[%rd49+24], %rd83;
	mul.wide.u32 	%rd50, %r29, 4;
	sub.s64 	%rd16, %rd49, %rd50;
	ld.local.u32 	%r212, [%rd16+24];
	ld.local.u32 	%r213, [%rd16+20];
	and.b32  	%r35, %r27, 31;
	setp.eq.s32 	%p15, %r35, 0;
	@%p15 bra 	LBB0_20;

	mov.u32 	%r142, 32;
	sub.s32 	%r143, %r142, %r35;
	shr.u32 	%r144, %r213, %r143;
	shl.b32 	%r145, %r212, %r35;
	add.s32 	%r212, %r144, %r145;
	ld.local.u32 	%r146, [%rd16+16];
	shr.u32 	%r147, %r146, %r143;
	shl.b32 	%r148, %r213, %r35;
	add.s32 	%r213, %r147, %r148;

LBB0_20:
	shr.u32 	%r149, %r213, 30;
	shl.b32 	%r150, %r212, 2;
	or.b32  	%r215, %r149, %r150;
	shl.b32 	%r216, %r213, 2;
	shr.u32 	%r151, %r215, 31;
	shr.u32 	%r152, %r212, 30;
	add.s32 	%r42, %r151, %r152;
	setp.eq.s32 	%p16, %r151, 0;
	mov.u32 	%r214, %r32;
	@%p16 bra 	LBB0_22;

	not.b32 	%r153, %r215;
	neg.s32 	%r43, %r216;
	setp.eq.s32 	%p17, %r216, 0;
	selp.u32 	%r154, 1, 0, %p17;
	add.s32 	%r215, %r154, %r153;
	xor.b32  	%r214, %r32, -2147483648;
	mov.u32 	%r216, %r43;

LBB0_22:
	cvt.u64.u32 	%rd51, %r215;
	cvt.u64.u32 	%rd52, %r216;
	bfi.b64 	%rd53, %rd51, %rd52, 32, 32;
	cvt.rn.f64.s64 	%fd3, %rd53;
	mul.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f75, %fd4;
	neg.f32 	%f76, %f75;
	setp.eq.s32 	%p18, %r214, 0;
	selp.f32 	%f129, %f75, %f76, %p18;
	setp.eq.s32 	%p19, %r32, 0;
	neg.s32 	%r155, %r42;
	selp.b32 	%r217, %r42, %r155, %p19;

LBB0_24:
	and.b32  	%r51, %r217, 1;
	setp.eq.s32 	%p20, %r51, 0;
	selp.f32 	%f18, %f129, 0f3F800000, %p20;
	mul.rn.f32 	%f19, %f129, %f129;
	mov.f32 	%f130, 0fB94D4153;
	@%p20 bra 	LBB0_26;

	mov.f32 	%f79, 0fBAB607ED;
	mov.f32 	%f80, 0f37CBAC00;
	fma.rn.f32 	%f130, %f80, %f19, %f79;

LBB0_26:
	selp.f32 	%f81, 0f3C0885E4, 0f3D2AAABB, %p20;
	fma.rn.f32 	%f82, %f130, %f19, %f81;
	selp.f32 	%f83, 0fBE2AAAA8, 0fBEFFFFFF, %p20;
	fma.rn.f32 	%f84, %f82, %f19, %f83;
	fma.rn.f32 	%f86, %f19, %f18, %f71;
	fma.rn.f32 	%f131, %f84, %f86, %f18;
	and.b32  	%r156, %r217, 2;
	setp.eq.s32 	%p22, %r156, 0;
	@%p22 bra 	LBB0_28;

	mov.f32 	%f88, 0fBF800000;
	fma.rn.f32 	%f131, %f131, %f88, %f71;

LBB0_28:
	mul.f32 	%f89, %f2, %f131;
	mul.f32 	%f90, %f1, %f128;
	sub.f32 	%f25, %f90, %f89;
	mov.u32 	%r224, %r231;
	mov.f32 	%f132, %f135;
	@%p1 bra 	LBB0_38;

	setp.eq.f32 	%p24, %f4, 0f7F800000;
	@%p24 bra 	LBB0_37;
	bra.uni 	LBB0_30;

LBB0_37:
	mul.rn.f32 	%f132, %f47, %f71;
	mov.u32 	%r224, %r231;
	bra.uni 	LBB0_38;

LBB0_30:
	mov.b32 	%r52, %f47;
	bfe.u32 	%r158, %r52, 23, 8;
	add.s32 	%r53, %r158, -128;
	shl.b32 	%r159, %r52, 8;
	or.b32  	%r54, %r159, -2147483648;
	shr.u32 	%r55, %r53, 5;
	add.u64 	%rd56, %SP, 0;
	add.u64 	%rd85, %SPL, 0;
	mov.u64 	%rd86, 0;
	mov.u32 	%r218, 0;
	mov.u64 	%rd84, __cudart_i2opi_f;

LBB0_31:
	.pragma "nounroll";
	ld.global.nc.u32 	%r160, [%rd84];
	mad.wide.u32 	%rd57, %r160, %r54, %rd86;
	shr.u64 	%rd86, %rd57, 32;
	st.local.u32 	[%rd85], %rd57;
	add.s64 	%rd85, %rd85, 4;
	add.s64 	%rd84, %rd84, 4;
	add.s32 	%r218, %r218, 1;
	setp.ne.s32 	%p25, %r218, 6;
	@%p25 bra 	LBB0_31;

	and.b32  	%r58, %r52, -2147483648;
	cvta.to.local.u64 	%rd59, %rd56;
	st.local.u32 	[%rd59+24], %rd86;
	mul.wide.u32 	%rd60, %r55, 4;
	sub.s64 	%rd24, %rd59, %rd60;
	ld.local.u32 	%r219, [%rd24+24];
	ld.local.u32 	%r220, [%rd24+20];
	and.b32  	%r61, %r53, 31;
	setp.eq.s32 	%p26, %r61, 0;
	@%p26 bra 	LBB0_34;

	mov.u32 	%r161, 32;
	sub.s32 	%r162, %r161, %r61;
	shr.u32 	%r163, %r220, %r162;
	shl.b32 	%r164, %r219, %r61;
	add.s32 	%r219, %r163, %r164;
	ld.local.u32 	%r165, [%rd24+16];
	shr.u32 	%r166, %r165, %r162;
	shl.b32 	%r167, %r220, %r61;
	add.s32 	%r220, %r166, %r167;

LBB0_34:
	shr.u32 	%r168, %r220, 30;
	shl.b32 	%r169, %r219, 2;
	or.b32  	%r222, %r168, %r169;
	shl.b32 	%r223, %r220, 2;
	shr.u32 	%r170, %r222, 31;
	shr.u32 	%r171, %r219, 30;
	add.s32 	%r68, %r170, %r171;
	setp.eq.s32 	%p27, %r170, 0;
	mov.u32 	%r221, %r58;
	@%p27 bra 	LBB0_36;

	not.b32 	%r172, %r222;
	neg.s32 	%r69, %r223;
	setp.eq.s32 	%p28, %r223, 0;
	selp.u32 	%r173, 1, 0, %p28;
	add.s32 	%r222, %r173, %r172;
	xor.b32  	%r221, %r58, -2147483648;
	mov.u32 	%r223, %r69;

LBB0_36:
	cvt.u64.u32 	%rd61, %r222;
	cvt.u64.u32 	%rd62, %r223;
	bfi.b64 	%rd63, %rd61, %rd62, 32, 32;
	cvt.rn.f64.s64 	%fd5, %rd63;
	mul.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f91, %fd6;
	neg.f32 	%f92, %f91;
	setp.eq.s32 	%p29, %r221, 0;
	selp.f32 	%f132, %f91, %f92, %p29;
	setp.eq.s32 	%p30, %r58, 0;
	neg.s32 	%r174, %r68;
	selp.b32 	%r224, %r68, %r174, %p30;

LBB0_38:
	add.s32 	%r77, %r224, 1;
	and.b32  	%r78, %r77, 1;
	setp.eq.s32 	%p31, %r78, 0;
	selp.f32 	%f29, %f132, 0f3F800000, %p31;
	mul.rn.f32 	%f30, %f132, %f132;
	mov.f32 	%f133, 0fB94D4153;
	@%p31 bra 	LBB0_40;

	mov.f32 	%f95, 0fBAB607ED;
	mov.f32 	%f96, 0f37CBAC00;
	fma.rn.f32 	%f133, %f96, %f30, %f95;

LBB0_40:
	selp.f32 	%f97, 0f3C0885E4, 0f3D2AAABB, %p31;
	fma.rn.f32 	%f98, %f133, %f30, %f97;
	selp.f32 	%f99, 0fBE2AAAA8, 0fBEFFFFFF, %p31;
	fma.rn.f32 	%f100, %f98, %f30, %f99;
	fma.rn.f32 	%f102, %f30, %f29, %f71;
	fma.rn.f32 	%f134, %f100, %f102, %f29;
	and.b32  	%r175, %r77, 2;
	setp.eq.s32 	%p33, %r175, 0;
	@%p33 bra 	LBB0_42;

	mov.f32 	%f104, 0fBF800000;
	fma.rn.f32 	%f134, %f134, %f104, %f71;

LBB0_42:
	mul.f32 	%f36, %f2, %f134;
	@%p1 bra 	LBB0_52;

	setp.eq.f32 	%p35, %f4, 0f7F800000;
	@%p35 bra 	LBB0_51;
	bra.uni 	LBB0_44;

LBB0_51:
	mul.rn.f32 	%f135, %f47, %f71;
	bra.uni 	LBB0_52;

LBB0_44:
	mov.b32 	%r79, %f47;
	bfe.u32 	%r177, %r79, 23, 8;
	add.s32 	%r80, %r177, -128;
	shl.b32 	%r178, %r79, 8;
	or.b32  	%r81, %r178, -2147483648;
	shr.u32 	%r82, %r80, 5;
	add.u64 	%rd66, %SP, 0;
	add.u64 	%rd88, %SPL, 0;
	mov.u64 	%rd89, 0;
	mov.u32 	%r225, 0;
	mov.u64 	%rd87, __cudart_i2opi_f;

LBB0_45:
	.pragma "nounroll";
	ld.global.nc.u32 	%r179, [%rd87];
	mad.wide.u32 	%rd67, %r179, %r81, %rd89;
	shr.u64 	%rd89, %rd67, 32;
	st.local.u32 	[%rd88], %rd67;
	add.s64 	%rd88, %rd88, 4;
	add.s64 	%rd87, %rd87, 4;
	add.s32 	%r225, %r225, 1;
	setp.ne.s32 	%p36, %r225, 6;
	@%p36 bra 	LBB0_45;

	and.b32  	%r85, %r79, -2147483648;
	cvta.to.local.u64 	%rd69, %rd66;
	st.local.u32 	[%rd69+24], %rd89;
	mul.wide.u32 	%rd70, %r82, 4;
	sub.s64 	%rd32, %rd69, %rd70;
	ld.local.u32 	%r226, [%rd32+24];
	ld.local.u32 	%r227, [%rd32+20];
	and.b32  	%r88, %r80, 31;
	setp.eq.s32 	%p37, %r88, 0;
	@%p37 bra 	LBB0_48;

	mov.u32 	%r180, 32;
	sub.s32 	%r181, %r180, %r88;
	shr.u32 	%r182, %r227, %r181;
	shl.b32 	%r183, %r226, %r88;
	add.s32 	%r226, %r182, %r183;
	ld.local.u32 	%r184, [%rd32+16];
	shr.u32 	%r185, %r184, %r181;
	shl.b32 	%r186, %r227, %r88;
	add.s32 	%r227, %r185, %r186;

LBB0_48:
	shr.u32 	%r187, %r227, 30;
	shl.b32 	%r188, %r226, 2;
	or.b32  	%r229, %r187, %r188;
	shl.b32 	%r230, %r227, 2;
	shr.u32 	%r189, %r229, 31;
	shr.u32 	%r190, %r226, 30;
	add.s32 	%r95, %r189, %r190;
	setp.eq.s32 	%p38, %r189, 0;
	mov.u32 	%r228, %r85;
	@%p38 bra 	LBB0_50;

	not.b32 	%r191, %r229;
	neg.s32 	%r96, %r230;
	setp.eq.s32 	%p39, %r230, 0;
	selp.u32 	%r192, 1, 0, %p39;
	add.s32 	%r229, %r192, %r191;
	xor.b32  	%r228, %r85, -2147483648;
	mov.u32 	%r230, %r96;

LBB0_50:
	cvt.u64.u32 	%rd71, %r229;
	cvt.u64.u32 	%rd72, %r230;
	bfi.b64 	%rd73, %rd71, %rd72, 32, 32;
	cvt.rn.f64.s64 	%fd7, %rd73;
	mul.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f105, %fd8;
	neg.f32 	%f106, %f105;
	setp.eq.s32 	%p40, %r228, 0;
	selp.f32 	%f135, %f105, %f106, %p40;
	setp.eq.s32 	%p41, %r85, 0;
	neg.s32 	%r193, %r95;
	selp.b32 	%r231, %r95, %r193, %p41;

LBB0_52:
	and.b32  	%r104, %r231, 1;
	setp.eq.s32 	%p42, %r104, 0;
	selp.f32 	%f40, %f135, 0f3F800000, %p42;
	mul.rn.f32 	%f41, %f135, %f135;
	mov.f32 	%f136, 0fB94D4153;
	@%p42 bra 	LBB0_54;

	mov.f32 	%f109, 0fBAB607ED;
	mov.f32 	%f110, 0f37CBAC00;
	fma.rn.f32 	%f136, %f110, %f41, %f109;

LBB0_54:
	selp.f32 	%f111, 0f3C0885E4, 0f3D2AAABB, %p42;
	fma.rn.f32 	%f112, %f136, %f41, %f111;
	selp.f32 	%f113, 0fBE2AAAA8, 0fBEFFFFFF, %p42;
	fma.rn.f32 	%f114, %f112, %f41, %f113;
	fma.rn.f32 	%f116, %f41, %f40, %f71;
	fma.rn.f32 	%f137, %f114, %f116, %f40;
	and.b32  	%r194, %r231, 2;
	setp.eq.s32 	%p44, %r194, 0;
	@%p44 bra 	LBB0_56;

	mov.f32 	%f118, 0fBF800000;
	fma.rn.f32 	%f137, %f137, %f118, %f71;

LBB0_56:
	fma.rn.f32 	%f119, %f1, %f137, %f36;
	add.f32 	%f120, %f119, 0f3F000000;
	add.f32 	%f121, %f25, 0f3F000000;
	tex.2d.v4.f32.f32 	{%f122, %f123, %f124, %f125}, [tex, {%f121, %f120}];
	mad.lo.s32 	%r203, %r114, %r105, %r110;
	cvta.to.global.u64 	%rd75, %rd33;
	mul.wide.u32 	%rd76, %r203, 4;
	add.s64 	%rd77, %rd75, %rd76;
	st.global.f32 	[%rd77], %f122;
	ret;

}

